{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af04e4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"cs109b_hw6.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a2d0b-c6a0-4695-8ba7-999ad6977d0c",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> Data Science 2: Advanced Topics in Data Science \n",
    "## Homework 6: Transformers\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2024**<br/>\n",
    "**Instructors**: Pavlos Protopapas & Alex Young\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c42f27-1f75-403f-ba38-248bedc64943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/\"\n",
    "    \"content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f8f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import os \n",
    "import time\n",
    "import random\n",
    "# import gensim # for loading word2vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# specific machine learning functionality\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification , TFDebertaV2ForSequenceClassification\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2' # Trying to reduce tensorflow warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467ddce3-588b-4d96-83f6-eb55b5000761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure notebook runtime\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b00b01-087d-44d3-8aa5-8fcef488e19d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "### **Pre-Trained Transformers for Text Classification**\n",
    "\n",
    "Throughout CS109A and CS109B, we've modeled many classification tasks using various machine learning algorithms. NLP has several sub-fields/popular problems that are largely treated as classification tasks, such as sentiment analysis, natural language entailment, and generic '*text classification*' like spam detection. Moreover, *nearly all* NLP problems have at least some classification component.\n",
    "\n",
    "In part 2 of this assignment, we will focus on using *transformers* for text classification, a popular and powerful technique in NLP. Transformers are a type of neural network architecture that has gained widespread popularity in recent years due to their ability to effectively model long-range dependencies in text.\n",
    "\n",
    "In the real world, one common text classification task is the **Systematic Review**, a process of classifying research papers for a particular research topic. In this part of this assignment, you will implement a text classifier for the Systematic Review process.\n",
    "\n",
    "Medical research is produced at an astronomical rate, with [a few thousand articles published daily](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3191655/). Conducting a proper literature search can be unwieldy and overwhelming, requiring very carefully crafted search terms, and sifting through several thousand results. A doctor reads the **abstracts** of thousands of candidate papers, looking for potentially useful research papers. Often, the Systematic Review only yields a handful of useful research papers, and the others are considered **irrelevant**.\n",
    "\n",
    "If the Systematic Review yields many useful papers, then one might be able to conduct a *Meta Analysis*, allowing one to draw new insights and research conclusions from the myriad of independent, regionalized research through the world. So, one needs to be incredibly meticulous when reading through thousands of abstracts. NLP can assist in this task by helping to classify papers as relevant or irrelevant.\n",
    "\n",
    "In this real-life situation, an infectious disease doctor is researching sexually transmitted infections (STIs) in women who have HIV and are living in sub-Saharan Africa. STIs like gonorrhea and chlamydia are under-treated in low-resource communities. Because there aren't affordable and accessible STI testing in the area, there isn't population-wide screen. So, doctors don't have a good understanding of the epidemiology and prevalence of STIs -- especially amongst women who have HIV, which carries extra, serious health risks.\n",
    "    \n",
    "Let's build a text classifier to see if we can help find \"**not irrelevant**\" abstracts. We will train the model by providing many already-annotated abstracts, where each abstract is labelled as being either \"*irrelevant*\" or \"*not irrelevant*\". At test time, we will see if your model can help suggest which papers to strongly consider.\n",
    "\n",
    "Note that the distinction between \"*irrelevant*\" and \"*not irrelevant*\" is not the same as the distinction between \"*important*\" and \"*unimportant*\". Some papers may be highly relevant to a particular research topic but not necessarily \"*important*\" in the sense of having groundbreaking findings or significant implications.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7b9bf6-12df-4db8-a791-3bd08a0b4b9a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**1.1 - Loading the Abstract Data**\n",
    "\n",
    "Load the data from the CSV files `review_78678_irrelevant.csv`, `review_78678_not_irrelevant_included.csv`, and `review_78678_not_irrelevant_excluded.csv` into 3 dataframes. For each dataframe, add a new column called `target` with a value of `0` for `review_78678_irrelevant.csv` and a value of `1` for the other two files. The CSV files can be found in the `./data` directory.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cd111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3246a8a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">\n",
    "   \n",
    "**1.2 - Combine the Dataframes**\n",
    "    \n",
    "Concatenate all the dataframes into a single dataframe. Keep only the columns `Abstract` and `target`. Apply `dropna()` on the dataframe. Name the final dataframe `all_data_df`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94669c86-9231-4d31-abf3-d92748ad7348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a156e-0d32-40b3-a345-5ecd2b94e31a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display summary information\n",
    "print(\"Shape:\",all_data_df.shape)\n",
    "print(all_data_df.target.value_counts(normalize=True))\n",
    "all_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417506c0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**1.3 - Train / Validation Split**\n",
    "\n",
    "Use `train_test_split` to split the dataset into 90% train and 10% validation. You should stratify on the the target variable and use a random state of `109`. Name the resulting variables `train_x`, `validate_x`, `train_y`, and `validate_y`.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb102a-3742-43cc-ab47-acf87df55a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4f7f0-a3d2-4b69-aef2-0e2ce27fc8d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Display split sizes\n",
    "print(\"train_x count:\", len(train_x))\n",
    "print(\"validate_x count:\", len(validate_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379a7f1-21fc-4da0-ae43-21c41c84d8c3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "**1.4 - BERT Tokenization**\n",
    "    \n",
    "Per-trained models expect their inputs to have been processed in a particular way. We need to make sure we use the same tokenizer to processor data that was used to process the data our BERT model was trained on.\n",
    "    \n",
    "- Use `AutoTokenizer` to load the tokenizer for `'bert-base-uncased'`. Be sure to set `do_lower_case=True`.\n",
    "- Use the tokenizer object to process both train and validation data, setting `max_length` to a value suitable for the dataset. It would need to be `<=512`.\n",
    "- Save the processed input data as `train_x_processed` and `validate_x_processed`.\n",
    "\n",
    "**Note:** The output from the tokenizer is a dictionary. We'll be interested in the keys `'input_ids'` and `'attention_mask'`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970870c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6237e89c-f9cd-471b-868e-39b7c54485c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f5bba5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Display keys in processed input dictionary\n",
    "print(train_x_processed.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b8c05",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Display shapes and examples of processed input\n",
    "print(\"train_x_processed shape:\", train_x_processed[\"input_ids\"].shape)\n",
    "print(\"validate_x_processed shape:\", validate_x_processed[\"input_ids\"].shape)\n",
    "# First sample\n",
    "print(\"First sample:\")\n",
    "print(\"input_ids:\",train_x_processed[\"input_ids\"][0][:10])\n",
    "print(\"attention_mask:\",train_x_processed[\"attention_mask\"][0][:10])\n",
    "# Second sample\n",
    "print(\"Second sample:\")\n",
    "print(\"input_ids:\",train_x_processed[\"input_ids\"][1][:10])\n",
    "print(\"attention_mask:\",train_x_processed[\"attention_mask\"][1][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ce274",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**1.5 - Dataset Pipeline** \n",
    "    \n",
    "Build two tf.data pipelines: one for training and another validation. Follow this order when building pipelines:\n",
    "  * Shuffle (if necessary) \n",
    "  * Batch\n",
    "  * Prefetch\n",
    "\n",
    "**Hint:** You can use the now familiar `from_tensor_slices` method to create your Tensorflow Dataset objects. But where as previously you've only needed to pass `x` and `y` as a tuple, here you will need to pass the input ids, attention mask, and the target variable as a 3-tuple.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058149ba-5bb9-47a0-bf6e-c4b7631007bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct your dataset pipeline\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16df28b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Display some pipeline info\n",
    "print(\"train_data:\\n\", train_data)\n",
    "print(\"validation_data:\\n\", validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b621b51",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\"> \n",
    "\n",
    "**1.6 - Build Pre-Trained BERT**\n",
    "\n",
    "Build and compile the pretrained `'bert-base-uncased'` model using [TFAutoModelForSequenceClassification](TFAutoModelForSequenceClassification). Make sure to display model summary. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a9a6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92173f-c5f8-4739-8eff-2c5a46f08e09",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**1.7 - Fit BERT to Classification the Task**\n",
    "\n",
    "Fit the `'bert-base-uncased'` model using your train pipeline while also monitoring performance on the validation set. After fitting, create a well labeled plot of the training history.\n",
    "    \n",
    "Some suggestions to ensure validation accuracy > 0.9: \n",
    "- Try smaller learning rates (~2e-5)\n",
    "- Try limiting epochs 5 or fewer (Each epoch takes ~4 mins on JupyterHub)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf67c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train BERT\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077554e4-6e7b-49d5-add4-511d65e97477",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035bc7f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">  \n",
    "\n",
    "**1.8 - DeBERTa**\n",
    "\n",
    "Repeat the tokenization, pipeline, model building, and fitting steps above (2.4-2.7), but now for the [DeBERTa](https://huggingface.co/docs/transformers/model_doc/deberta) base model. Specifically, we'll use the [V3](https://huggingface.co/microsoft/deberta-v3-base) model (`'microsoft/deberta-v3-base'`).  You may be able to use code from the previous BERT model questions if you wrote utility functions. \n",
    "\n",
    "**Don't forget to display important output like the model's summary and a plot of the training history!**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a536b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenization & Pipelines\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91162f4d-17f3-4f49-b926-389b7824e935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build DeBERTa\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e979f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd28f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train DeBERTa\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dc760",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Plot Training History\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad595a01",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\">  \n",
    "\n",
    "**1.9 - Model Results**\n",
    "\n",
    "\n",
    "- Display confusion matrices for both the BERT and DeBERTa models.\n",
    "- Decode and display 4 abstracts considered highly *not irrelevant* by the two models (two from each)\n",
    "- Do the same for 4 abstracts considered highly *not relevant* by the two models\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b38df-d3d3-4740-a551-ec7bb755d8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec226f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion Matrices\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e165c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4 NOT irrelevant abstracts according to each model\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab7dd8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4 NOT relevant abstracts (i.e., 4 irrelevant abstracts) according to each model\n",
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f125a7c2-e9b1-4975-b130-41e0cc9896a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" style=\"color: #333; background-color: #e8fffb; border-color: #bcfff2; border-width: 1px; border-radius: 3px; padding: 10px;\"> \n",
    "\n",
    "**1.10 - Model Comparison**\n",
    "    \n",
    "Finally, address the following questions in the markdown cell provided:\n",
    "- Based on the earlier plotted training histories  what are your thoughts on the performance of the two models both in absolute terms and with respect to one another?\n",
    "- Based on the confusion matrices do you see a significant difference in the types of errors each model makes?\n",
    "- Are you convinced by the abstracts displayed above that the models are performing well in their classification task?  Are the results qualitatively distinct between the two models?\n",
    "- Did you end up using identical hyperparameters and training procedures for both models? Why or why not?\n",
    "- What are 2 ways in which the DeBERTa model's use of poisitional encoding differs from the approach desribed in the lecture on BERT? (You may want to peruse [the original paper](https://arxiv.org/abs/2006.03654) for insights.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271917af-066e-4ec9-99a1-121bbbc4fcc6",
   "metadata": {},
   "source": [
    "**Your Answer Here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400c0fc-d5a3-416d-ac14-6cdbc2b2d035",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-info\" style=\"color: #4a4a4a; background-color: #fbe8ff; border-color: #eed4db; border-width: 1px; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "**Wrap-up**\n",
    "\n",
    "* In a few sentences, please describe the aspect(s) of the assignment you found most challenging. This could be conceptual and/or related to coding and implementation.\n",
    "\n",
    "* How many hours did you spend working on this assignment? Store this as an int or float in `hours_spent_on_hw`. If you worked on the project in a group, report the *average* time spent per person.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e0663-3438-4b12-b67e-e8148c255dff",
   "metadata": {},
   "source": [
    "**Your Answer Here**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ff42b-dc88-409c-aa43-61b87d14e0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hours_spent_on_hw = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67cd9a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"wrapup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42349484-7313-4e88-b9e9-f69965e2d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_end = time.time()\n",
    "print(f\"It took {(time_end - time_start)/60:.2f} minutes for this notebook to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf61cd-d830-46dc-85d7-c8a1280dccb4",
   "metadata": {},
   "source": [
    "**This concludes HW6. Thank you!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e82cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "wrapup": {
     "name": "wrapup",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert float(hours_spent_on_hw), 'Please select a time in hours (int or float) to specify how long you spent on this assignment.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
