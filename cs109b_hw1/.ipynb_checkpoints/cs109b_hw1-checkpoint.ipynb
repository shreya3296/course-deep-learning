{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"cs109b_hw1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "## Homework 1 - Clustering\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2024**<br/>\n",
    "**Instructors**: Pavlos Protopapas & Alex Young\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"background: lightsalmon; border: thin solid black; border-radius: 2px; padding: 5px\">\n",
    "\n",
    "### Instructions\n",
    "- To submit your notebook, follow the instructions given in on the Canvas assignment page.\n",
    "- Plots should be legible and interpretable *without having to refer to the code that generated them*. They should includelabels for the $x$- and $y$-axes as well as a descriptive title and/or legend when appropriate.\n",
    "- When asked to interpret a visualization, do not simply describe it (e.g., \"the curve has a steep slope up\"), but instead explain what you believe the plot *means*.\n",
    "- Autograding tests are mostly to help you debug. The tests are not exhaustive so simply passing all tests may not be sufficient for full credit.\n",
    "- The use of *extremely* inefficient or error-prone code (e.g., copy-pasting nearly identical commands rather than looping) may result in only partial credit.\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. Please get course staff approval before importing any additional 3rd party libraries.\n",
    "- Enable scrolling output on cells with very long output.\n",
    "- Feel free to add additional code or markdown cells as needed.\n",
    "- Ensure your code runs top to bottom without error and passes all tests by restarting the kernel and running all cells (note that this can take a few minutes). \n",
    "- **You should do a \"Restart Kernel and Run All Cells\" before submitting to ensure (1) your notebook actually runs and (2) all output is visible**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from gap_statistic import OptimalK\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure notebook runtime\n",
    "time_start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "# Notebook Contents\n",
    "\n",
    "- [**Problem 1 [37.5 pts]: Clustering with k-means**](#part1)\n",
    "\n",
    "- [**Problem 2 [37.5 pts]: Other Ks**](#part2)\n",
    "  \n",
    "- [**Problem 3 [25 pts]: DBSCAN**](#part3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = \"background: lightsalmon; border: thin solid black; border-radius: 2px; padding: 5px\">\n",
    "\n",
    "### The Dataset\n",
    "In this assignment, you will be working with data collected from The Free Music Archive (https://freemusicarchive.org/). The Free Music Archive is an online repository of original music from independent artists that can be freely downloaded as an mp3. \n",
    "\n",
    "- the provided `fma_new.csv` contains 9,354 rows\n",
    "\n",
    "- each music track is represented by a total of 82 summary audio features\n",
    "\n",
    "- 8 interpretable features extracted by Echonest (now Spotify):\\\n",
    "`acousticness`, `danceability`, `energy`, `instrumentalness`, `liveness`, `speechiness`, `tempo`, `valence`\n",
    "\n",
    "- 74 abstract audio features computated across the run time of the track using the [librosa](https://librosa.org/doc/latest/index.html) python package and then averaged. \n",
    "\n",
    "For those interested in more information about the FMA dataset please see the paper and GitHub repository (https://github.com/mdeff/fma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"part1\"></a>\n",
    "\n",
    "## <div class='exercise'>Part 1: Clustering with k-means </div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q1.1 Loading Data, Scaling, and KMeans Clustering</b></div>\n",
    "    \n",
    "1. **Load Data**: Read `data/fma_new.csv` into a DataFrame named `fma`.\n",
    "\n",
    "2. **Standardize Data**: Standardize `fma` so all features in the dataset have a mean of 0 and a standard deviation of 1. Save the result in a DataFrame called `fma_scaled`, ensuring you have the exact same column names as `fma`.\n",
    "\n",
    "3. **K-Means Clustering**: Run k-means clustering on `fma_scaled` with the following parameters:\n",
    "   - Number of clusters (`n_clusters`): 12\n",
    "   - Number of centroid initializations (`n_init`): 25\n",
    "   - Random state (`random_state`): 109\n",
    "     \n",
    "4. **Save the fitted KMeans model as `km12`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q1.2 Evaluating $k=12$</b></div>\n",
    "\n",
    "<br>\n",
    "The `silplot` function provided below creates two subplots: one displays the silhouette scores for each data point across all clusters and the other shows a projection of the data onto its first 2 principal components. In both subplots, the assigned cluster labels are encoded by color.\n",
    "\n",
    "How reasonable does the clustering with $k=12$ appear? Use your understanding of the silhouette scores and information on the PCA projection plot to support your position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#modified code from http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "def silplot(X, cluster_labels, clusterer, pointlabels=None):\n",
    "    n_clusters = clusterer.n_clusters\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(12,7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example we \n",
    "    # will set a lower limit on the x-axis to keep the plot small\n",
    "    ax1.set_xlim([-0.2, 1])\n",
    "    \n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette_score is {silhouette_avg}.\")\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(0,n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = plt.cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = plt.cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    \n",
    "    # axes will be first 2 PCA components\n",
    "    \n",
    "    pca = PCA(n_components=2).fit(X.values)\n",
    "    X_pca = pca.transform(X.values) \n",
    "    ax2.scatter(X_pca[:, 0], X_pca[:, 1], marker='.', s=200, lw=0, alpha=0.35,\n",
    "                c=colors, edgecolor='k')\n",
    "    xs = X_pca[:, 0]\n",
    "    ys = X_pca[:, 1]    \n",
    "\n",
    "    \n",
    "    if pointlabels is not None:\n",
    "        for i in range(len(xs)):\n",
    "            plt.text(xs[i],ys[i],pointlabels[i])\n",
    "\n",
    "    # Labeling the clusters (transform to PCA space for plotting)\n",
    "    centers = pca.transform(clusterer.cluster_centers_)\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % int(i), alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC1 ({}%)\".format(np.round(100*pca.explained_variance_ratio_[0],1)))\n",
    "    ax2.set_ylabel(\"PC2 ({}%)\".format(np.round(100*pca.explained_variance_ratio_[1],1)))\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<a id=\"part2\"></a>\n",
    "\n",
    "## <div class='exercise'>Part 2: Other Ks </div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "#### Overview\n",
    "In Part 1, we naively assumed $k=12$ clusters based on distinct genres in the dataset. In part 2, you will explore varying cluster numbers using metrics to determine clustering effectiveness.\n",
    "\n",
    "#### Data Sampling\n",
    "- Work with a 2,000 data points sample.\n",
    "- Use the Pandas `sample` method with `random_state=109`.\n",
    "- Store in `processed_sample`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.1 Inertia</b></div>\n",
    "\n",
    "Here you'll use the elbow method to evaluate the best choice of $k$, plotting the total inertia of each k-means clustering for $k \\in \\{1,2,...,15\\}.$\n",
    "\n",
    "Running `KMeans` across many values of $k$ can take a long time so we'll take a few steps to speed things up.\n",
    "\n",
    "First, you should only be clustering a subset of the scaled data in this section (part 2). Using the DataFrame's `sample` method with a `random_state` of 109, sample 2,000 data points and store them in `processed_sample`.\n",
    "\n",
    "Next, when fitting each KMeans object, use only 10 initializations and a random state of 109 as before.\n",
    "\n",
    "Finally, create a well-labeled plot of inertia as a function of $k$ and describe what value(s) of $k$ might be considered optimal with respect to this plot and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.2 Silhouette Score</b></div>\n",
    "\n",
    "Using the labels from each of the 15 fitted KMeans objects in the previous question, calculate the average silhouette scores and store them in `sil_scores`. \n",
    "\n",
    "Plot the average silhouette scores in `sil_scores` as a function of $k$. Describe what value(s) of $k$ might be considered optimal with respect to this plot and why.\n",
    "\n",
    "**Hints:**\n",
    "* If you stored your results from Q2.1 you shouldn't have to refit any KMeans objects here\n",
    "* `silhouette_score` will throw an error if you try and score labels containing only a single cluster. Note that the silhouette score when $k=1$ is defined to be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.3 Gap Statistic</b></div>\n",
    "\n",
    "Use the gap statistic to evaluate the choice of the number of clusters for k-means clustering with $k \\in \\{1,2,..,15\\}$. Again, use `processed_sample` rather than the entire dataset to save time. \n",
    "\n",
    "Create a well-labeled plot showing the gap statistic as a function of the number of clusters.\n",
    "\n",
    "Describe the rule for picking the optimum number of clusters described in [the original gap statistic paper](https://hastie.su.domains/Papers/gap.pdf). This is the method referred to in lab as the \"slack\" rule. You'll need to use $\\LaTeX$ in a markdown cell to communicate this clearly.\n",
    "\n",
    "Finally, demonstrate which value of $k$ is suggested by your results when using this \"slack\" rule. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Note:** You may attempt to implement the the gap statistic yourself or use the package demonstrated in lab. Just be aware that the package has [difficulties with reproducibility](https://github.com/milesgranger/gap_statistic/issues/59) so don't worry if your results change across runs. Setting a random seed with numpy and setting OptimalK's `n_jobs=1` helps, but it makes everything run unbearably slow. \n",
    "\n",
    "**Hint:** The [gap_statistic GitHub repo](https://github.com/milesgranger/gap_statistic) is a good place to find information about the `OptimalK` object and its attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.4 Choose a Best $k$</b></div>\n",
    "\n",
    "After analyzing the plots produced by all three of these metrics, discuss the number of k-means clusters that you think is the best fit for this dataset. Defend your answer with evidence from the three graphs produced here and what you surmise about this dataset. Store your choice in `best_k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q2.5 Visualize & Interpret Best $k$ Results</b></div>\n",
    "\n",
    "Fit KMeans on the *entire scaled dataset* using your choice of `best_k`, 25 initializations, and a random state of 109. Store the KMeans object in `km_best` and the resulting labels in `km_labels`. \n",
    "\n",
    "Next, use `silplot` to visualize these clusters and their silhouette scores. \n",
    "\n",
    "How do these plots differ from the previous pair, and what might that mean about the clusterings? Would you consider your kmeans clustering with `best_k` successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<a id=\"part3\"></a>\n",
    "\n",
    "## <div class='exercise'>Part 3: DBSCAN </div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q3.1: DBSCAN</b></div>\n",
    "\n",
    "Create a well-labeled knee plot to determine an optimal epsilon for when the min point parameter is 5. Then run DBSCAN on the data using your choice of `episilon` and the speficied `min_samples=5`.\n",
    "\n",
    "Store all labels produced in `dbscan_labels`.\\\n",
    "Store the number of *clusters* found by the algorithm in `dbscan_n_clusters`.\n",
    "\n",
    "Inspect the number of points that were assigned to each *label*. What does this tell you about the clusters and give a geometric interpretation of what kind of data might lead to this result of DBSCAN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class='exercise'><b>Q3.2</b></div>\n",
    "\n",
    "Load `data/track_info.csv` into the Dataframe `track_info` and inspect it. This track info corresponds to the data in `fma` row-for-row.\n",
    "\n",
    "Create a well-labeled plot or set of subplots that visualize the 'top genre' make-up of each cluster designated by the two sets of labels: `km_labels` and `dbscan_labels`.\n",
    "\n",
    "What does your visualization demonstrate about how each clustering compares to the genre labels? Does one clustering seem more successful at capturing genre distinctions?\n",
    "\n",
    "**Hint:** There are many ways you could approach this visualization task. Experiment! You may also find it helpful to create plotting functions to handle some parts of the visualization if they are being repeated with slightly different parameters (e.g., cluster labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<a id=\"bonus\"></a>\n",
    "\n",
    "## <div class='exercise'>Wrap-up</div>\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The only required section here is to report the amount of time you spent on this assignment.\n",
    "\n",
    "You are encouraged to use this space to continue to explore the fma dataset. You could:\n",
    "- Try different clustering methods (e.g., total linkage)\n",
    "- Attempt feature selection, engineering, or dimentionality reduction before clustering\n",
    "- Sample points from clusters and inspect their track information to get an idea what a cluster might represent\n",
    "- Find the nearest neighbors in the feature space to a track of interest\n",
    "- Pull in new data from the [FMA project](https://github.com/mdeff/fma). There are thousands of additional tracks to use (these were just the only ones that also had the Spotify features and track info available). And there are also hundreds of additional (abstract) audio feature columns that can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "How many hours did you spend working on this assignment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_spent_on_hw = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your additional (optional) code here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"wrap-up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_end = time.time()\n",
    "print(f\"It took {(time_end - time_start)/60:.2f} minutes for this notebook to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŒˆ **This concludes HW1. Thank you!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1.1": {
     "name": "q1.1",
     "points": 22,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(fma) == pd.DataFrame, f'fma should be a DataFrame'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert fma.shape == (9354, 82), f'fma should have shape (9354, 82), but you have {fma_scaled.shape}'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert fma_scaled.shape == (9354, 82), f'fma_scaled should have shape (9354, 82), but you have {fma_scaled.shape}'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert np.allclose(fma_scaled.mean(), 0), f'features in fma_scaled should all have mean zero (or very close to zero),  but you have {fma_scaled.mean()}'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert np.allclose(fma_scaled.std(), 1, atol=0.0001), f'features in fma_scaled should all have standard deviation 1 (or very close to 1),  but you have {fma_scaled.std()}'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert type(fma_scaled) == pd.DataFrame, f'fma_scaled should be a DataFrame'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert all(fma.columns == fma_scaled.columns), 'fma and fma_scaled should have the same column names'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert type(km12) == KMeans, 'km12 should be an sklearn KMeans object'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert km12.n_clusters == 12, 'km12 should have been fit with 12 clusters'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert km12.random_state == 109, 'km12 should have been fit with a random_state of 109'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> assert km12.n_init == 25, 'km12 should have been fit with 25 initializations'\n",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.1": {
     "name": "q2.1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert processed_sample.shape == (2000, 82), f'processed_sample should have shape (2000, 82) but you have {processed_sample.shape}'\n",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(sil_scores) == 15, f'You should have 15 elements in sil_scores but you have {len(sil_scores)}'\n",
         "hidden": false,
         "locked": false,
         "points": 1.5
        },
        {
         "code": ">>> assert sil_scores[0] == 0, f'Remember that the silhouette score when there is a single cluster is defined to be 0.'\n",
         "hidden": false,
         "locked": false,
         "points": 1.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.4": {
     "name": "q2.4",
     "points": 2.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert best_k > 1 and best_k <= 15, 'Your choice of best k should really be an integer in [2, 15]'\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.5": {
     "name": "q2.5",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert type(km_best) == KMeans, 'km_best should be an sklearn KMeans object'\n>>> assert km_best.n_clusters == best_k, f'km_best should have been fit with {best_k} clusters'\n>>> assert km_best.random_state == 109, 'km_best should have been fit with a random_state of 109'\n>>> assert km_best.n_init == 25, 'km_best should have been fit with 25 initializations'\n>>> assert km_labels.shape[0] == fma_scaled.shape[0], f'km_labels should have {fma_scaled.shape[0]} elements, but it has {km_labels.shape[0]}'\n",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3.1": {
     "name": "q3.1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert (np.unique(dbscan_labels) >= 0).sum() == dbscan_n_clusters, 'Your dbscan_n_clusters is incorrect. Think about what the label values mean.'\n>>> assert dbscan_labels.shape[0] == fma_scaled.shape[0], f'dbscan_labels should have {fma_scaled.shape[0]} elements, but it has {dbsca_labels.shape[0]}'\n",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "wrap-up": {
     "name": "wrap-up",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert float(time_spent_on_hw), 'Please select a time in hours (int or float) to specify how long you spent on this assignment.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
