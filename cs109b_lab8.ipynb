{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \u003cimg style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"\u003e CS109B Introduction to Data Science\n",
                "\n",
                "## Lab 8:  CNNs, Autoencoders, and Transfer Learning\n",
                "\n",
                "**Harvard University**\u003cbr/\u003e\n",
                "**Spring 2024**\u003cbr/\u003e\n",
                "**Instructors**: Pavlos Protopapas \u0026 Alex Young\u003cbr/\u003e\n",
                "\u003cbr/\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ConnectionError",
                    "evalue": "HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /Harvard-IACS/2019-CS109B/master/content/styles/cs109.css (Caused by NewConnectionError('\u003curllib3.connection.HTTPSConnection object at 0x7f5a433b4550\u003e: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--\u003e 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---\u003e 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
                        "File \u001b[0;32m/usr/lib/python3.11/socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--\u003e 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
                        "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--\u003e 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--\u003e 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/connectionpool.py:1058\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-\u003e 1058\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--\u003e 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--\u003e 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
                        "\u001b[0;31mNewConnectionError\u001b[0m: \u003curllib3.connection.HTTPSConnection object at 0x7f5a433b4550\u003e: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--\u003e 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/connectionpool.py:799\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    797\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--\u003e 799\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--\u003e 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
                        "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /Harvard-IACS/2019-CS109B/master/content/styles/cs109.css (Caused by NewConnectionError('\u003curllib3.connection.HTTPSConnection object at 0x7f5a433b4550\u003e: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML\n\u001b[0;32m----\u003e 4\u001b[0m styles \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m      5\u001b[0m HTML(styles)\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---\u003e 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---\u003e 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--\u003e 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--\u003e 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
                        "File \u001b[0;32m/usr/lib/python3.11/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--\u003e 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
                        "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /Harvard-IACS/2019-CS109B/master/content/styles/cs109.css (Caused by NewConnectionError('\u003curllib3.connection.HTTPSConnection object at 0x7f5a433b4550\u003e: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))"
                    ]
                }
            ],
            "source": [
                "## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES\n",
                "import requests\n",
                "from IPython.core.display import HTML\n",
                "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\").text\n",
                "HTML(styles)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca id=\"contents\"\u003e\u003c/a\u003e\n",
                "\n",
                "## Notebook Contents\n",
                "- [**Using SEAS Jupyter Hub**](#jubyterhub)\n",
                "- [**Keras for CNNs**](#keras)\n",
                "    - [Layers of a CNN in Keras](#keras_layers)\n",
                "- [**Revisiting KMNIST**](#kmnist)\n",
                "    - [Baseline CNN Classifier](#baseline)\n",
                "    - [**Exercise:** Improving on Baseline Model](#improving)\n",
                "- [**Tensorflow Datasets**](#tfdatasets)\n",
                "    - [Loading Datasets](#loadds)\n",
                "    - [The Dataset Object](#dsobj)\n",
                "    - [Take, Cardinality, \u0026 Batch](#take)\n",
                "    - [Cache, Prefetch, \u0026 Shuffle](#cache)\n",
                "    - [Preprocessing with Datasets](#dspreproc)\n",
                "    - [Data Augmentation](#dataaug)\n",
                "- [**Transfer Learning**](#transfer_learning)\n",
                "    - [MobileNet](#mobilenet)\n",
                "\n",
                "    "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca id='jupyterhub'\u003e\u003c/a\u003e\n",
                "## Using SEAS JupyterHub-GPU [^](#contents \"Back to Contents\")\n",
                "\n",
                "\n",
                "\u003cimg src='fig/need-a-gpu.jpg' width='250px'\u003e\n",
                "\n",
                "SEAS and FAS are providing you with a Jupyter computing environment to use for your CS109B course work. It is accessible from 'JupyterHub' in the menu on the Canvas course page. The **GPU** available on these instances allow for much faster NN training. The libraries defined in your cs109b.yml (keras, tensorflow, pandas, etc.) are all pre-installed.\n",
                "\n",
                "**NOTE : This service funded by SEAS and FAS for the purposes of the class.**\n",
                "\n",
                "**NOTE NOTE NOTE: You are only to use JupyterHub-GPU for purposes directly related to CS109B coursework.**\n",
                "\n",
                "**Help us keep this service: Make sure you stop your instance as soon as you do not need it.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check if GPU is available and visible to TensorFlow\n",
                "import tensorflow as tf\n",
                "if tf.test.gpu_device_name():\n",
                "    print('GPU found')\n",
                "else:\n",
                "    print(\"No GPU found\")"
            ]
        },
        {
            "attachments": {
                "ec1d1aa0-3e29-4734-9171-fa26d58ed5cb.png": {
                    "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAAC0CAYAAAA9zQYyAAAABHNCSVQICAgIfAhkiAAADaZJREFUeF7tnWlsFtUXxk9LV2r7tqVASwsV/KBogkaNH4AoEdwQhYgL7rIIrrhHifwhxrjvgqIxboBbMCKCihqDGpdoNDGIRiIpCq1Q2lIL1JZC2/+5Q1oLvH07d+bM+96Z+9yPnXvPnPM8P6+XeWfuTevkRmhQICIKpEekDpQBBRwFADRAiJQCGT2rWZ+WFqniUIwdCozqsWrGDG2H59ZUCaCtsdqOQgG0HT5bUyWAtsZqOwoF0Hb4bE2VANoaq+0oFEDb4bM1VQJoa6y2o1AAbYfP1lQJoK2x2o5CAbQdPltTJYC2xmo7CgXQdvhsTZUA2hqr7SgUQNvhszVVAmhrrLajUABth8/WVAmgrbHajkIBtB0+W1MlgLbGajsKBdB2+GxNlQDaGqvtKBRA2+GzNVUCaGustqNQAG2Hz9ZUCaCtsdqOQgG0HT5bUyWAtsZqOwoF0Hb4bE2VANoaq+0oFEDb4bM1VQJoa6y2o1AAbYfP1lR50A7+Uao6a2iFq3Laa3dQe1ubq74mdsoqL+eDRfRPXmivq6f21lYTS/KVU+SATuNjNY787DPKHz/elTDtTU1UNXYstWzY4Kq/KZ3S09Op8pNPKH/CBE8ptVVV0cajjqKoHYEWqSWHmqeGrVjhGmZFQr9YjIavW0fZbG5YmvqPdtjq1Z5hVnVmjRhBBeefH5aSXecZKaDLX3qJYlOnui6+q2NGSQmN+PJLyior0x6b7AEK5so1a6hg4kTftx5w222+Y5gWIDJAF8+YQcWzZnnWN5PXouWvvup5fDIGpvEy48i1a0VgVvkeMW4c5R53XDJST9o9IgN0VmWlb9EyBg70HSOoAA7MH31E+WeeKXqLkttvF42X6mCRATrVQgZ5/26YzzpL/DY5J58sHjOVAQF0KtV3cW/nqc2HH1J+ADATH1i5c8kSF1mEpwuANtgr5x+A6mnG2WfLZ8kw/33rrdTwwgvysVMYMXLPoVOopeitHZg/+IAKzj1XNK4TTMF8yy1Uv2iRfOwUR8QMnWID4t2+G+ZJk+Jd9ve3CMOshMEM7Q8P8dGBwzx3LtUvXiyetykBAbQpTnAegcN8881U/9xzBlUsnwqWHPKaeoro/Jy9ahUVBLXMsABmJTxmaE/4yQ7qgjl23nmygVU0tWa+6Saqf/55+dgGRsQMnWJTeGKmYe+/T4BZxggALaOjpygHYF5FsSDeerNsZu4yAEsOTyj6HxQ0zDU33kgNEfsV0I3qANqNSsJ9HJhX8jIjoJm55oYbIvcLoFsLsORwq5RQP+cjhLffodjkyUIRe4ThZYbNMCslMEPLY9VrRAfmdxjmiy/utY/nCx0dVD1zJu187TXPIaIwEEAnycUDM/PbwcHMHzjsfP31JFVj7m2w5EiCN90wX3KJ/N3UzAyYu3UF0PKIHRRRwTz0rbcoFgDMne3tgPkQ/7DkCBDoLpgLp00Tv0sXzI1Ll4rHDnNAAB2Qew7Mb75JgcE8fTo1LlsWUPbhDYslRwDedcN86aXi0Z2ZGTD3qitm6F6l8XbBgfmNN6gwKJivuYYaly/3lpwFozBDC5rcDfNllwlGPRDKmZkBc5+6Aug+JXLXATC70ynoXlhyCCjswMzLgMKgZuarr6ZGXsag9a0AgO5bo4Q9umG+/PKE/bxcdJYZV11Fjfy0BM2dAlhyuNMpbi8HZn50VgiY4+qTij9ihvahugPzFVf4iBB/qJqZt155Jf3DvzCi6SmAGVpPr+7eQ/lFIMDsUbwAh2GG9iCugrmI17bSrXPfPtrC73w0rVwpHdqaeABa0+pAYeb3pJv4g1k07woAaA3tKl58MbiZ+aKLqIn35UDzpwDW0C71UzAXz57tsrf7bp18AtcWwOxesD56Aug+BFKXK3jL2cBgVssMzMwuXHDXBUuOPnRyYJ4zp49e+pe7Z2beMhdNTgHM0Am0rOB9LQBzAoEMvIQZuhdTKviIOD+navUS1vlz/VNPURNm5kQSeb6GGTqOdOW8sWFQMKvbFfF2AxmFhXHujD/5VQBA91QwI4PU04wB11/vV9eE49VBn+XYciChRl4vAugeyuWOGhXI04x45qhtwIr5hX00WQUAtKyeWtHKnnkmFMcxaxWV4s4AOoUG9CsooKErVpB6DRVNRgEALaOj5yh5Y8ZQyR13eB6PgQcrAKANIKL0gQcoZ+RIAzIJfwoA2gAP07KznU1p1FkraP4UAND+9BMbnXvCCTT4/vvF4tkaCEAb5PygefMob8xogzIKXyoA2iTP0tP5o9vllM4/8KB5UwBAe9MtsFFZw4dT2bPPBhY/6oEBtE+HG/io4Z38c7lkG3DddZR/xhmSIa2JBaB9WF336KNUw6e0/s1HqO394w8fkQ4Zyk87Kvhdj355eXIxLYkEoD0arWDedvfdzugOtcMR78+h9tOQapllZVSBXUa15QTQupLx0Wnb7ryzG+au4c0//EANTz+tGy1h/9iUKVQYwFEWCW8a8osAWsdAddzw3LlU98QTcUdtu+suav3tt7jXvP6xnNfnmYMHex1u3TgA7dLyrp3z6xcv7nVEJwO/lTc6VxvGSLV+sRiWHhpiAmgXYjkftPLX2W7OAWxZv57qH3/cRVT3XfInTKASPu4YrW8FAHQfGnXu3Ut/XXghNb33Xh89/7u8/d57qfWXX1z3d9Ox9LHHKJufUaMlVgBAJ9Cno7mZNp9zDu1avTpBr8MvdS89eGaXaun9+9Owd9/lF5ikIkYzDoDuxdf2pibafPrptGfdul56JP5zy6+/0o4HH0zcSfNq7okn0qD5/9McZVd3AB3H7/11dVQ1diypR3F+2o777qN/f/zRT4jDxg5asID6M9ho8RUA0Ifosr+2lqpOPZVaNmyIr5jGXzu5b7V66tHaqjEqcdc09WU6n7eSzi8yoR2uAFTpoYlaZmw65RRq/f33w5Xy+JfWTZuolmdqyZZzzDFU2suzcMn7hDEWgO7h2l6Gr23LFnEfdzz8MDV/841o3BL+geeI004TjRmFYAA6SS6q06w6Wlrk7qbenealR7+cHLmYEYgEoJNk4t6qKqrl59OSLbO8nIbw7qho/ykAoJNIQx1v0rjnq69E71jEh3LGpk4VjRnmYAA6ye5V82mzHbt3i95VvcCUUVQkGjOswQB0kp1rq6mh7ffcI3rXjAEDqGLpUtGYYQ0GoFPgXD1v17v7009F71wwaRIVz5ghGjOMwQB0ilyr5uOU1XNvyTaEP67NrqyUDBm6WAA6RZbtq6+nbcJ72qXzN4gVagemFNVkwm0BdApd2Pnyy7Tr449FM8gbPZpK+MsZWxuATrHzNXxIfXtjo2gWpbylWM6xx4rGDEswAJ1ip/Y1NDjfKUo2mzd/BNCSJHmM1cjbFUgfWJ97/PGktum1rQFoQxyv4V/81HvYkm0g7xuSx+9129QAtCFu7+dfD2uuvVY2G/UCE//gkp6ZKRvX4GgA2iBz1JnfTXzmimRTmz8OWbRIMqTRsQC0YfZUT59O6qsZyVY8ezYVTJwoGdLYWADaMGva+Uvz6lmzZLPiT8XL+Zm3DZs/AmhZdESi7Vqzhv7hl/clW2ZpqfMtYtQbgDbU4Rp+0WhfdbVodrHJk6mIX1+NcgPQhrrbzpvUVKujk3m/PMk2hN/0y+LZOqoNQBvs7O7PP6fGV14RzVBt/lge4X2nAbQoLvLBaubMoTb+HlGy5Y8fTyV88kAUG4A23FXndICZM8WXHqWPPELZI0YYXr1+egBaX7Okj9jzxRfUsGSJ6H2dzR/5R5yobf4IoEUxCS7YNn4jT22EI9mczR8XLJQMmfJYADrlFrhLIIiDidSdB82fT/1POsldEiHoBaBDYFJXis3ff08Nwodyqs0f1Q5MUdn8EUCHCGiVqvoOUfpgouyjj6bSJ58MmRLx0wXQ8XUx9q/O6QD8xbjkwUSqWLX5YxROrwXQxqLbe2ItP/9M9dIzKj/uKFaPB0PeAHRIDdw+bx61CmzK3rP8REfWhUWmyAAt8Uhrn/AvckFCIL302L12LTV//XWQKScldmSAbly2jHbw5/teW/O33zpr0zA1dSZi3UMP+U+Z1+W1/PguCi0yQCsztvOBOl6gbv7uO9o8bhx1CJ4Amyw4ahcupH9/+snX7dSnX35j+EpAcHAa/6+r+/3E9RH5HXQQbyweu+ACVzK1/fknbZ02LZQwdxWYM3Kkc4Zhem6uq5p7durgg0W3TJlCrRs3ao81ZcCoHq/YRhJoU4RGHslRoCfQkVpyJEc+3MVkBQC0ye4gN20FALS2ZBhgsgIA2mR3kJu2AgBaWzIMMFkBAG2yO8hNWwEArS0ZBpisAIA22R3kpq0AgNaWDANMVgBAm+wOctNWAEBrS4YBJisAoE12B7lpKwCgtSXDAJMVANAmu4PctBUA0NqSYYDJCgBok91BbtoKAGhtyTDAZAUAtMnuIDdtBQC0tmQYYLICANpkd5CbtgIAWlsyDDBZAQBtsjvITVsBAK0tGQaYrACANtkd5KatAIDWlgwDTFYAQJvsDnLTVgBAa0uGASYrAKBNdge5aSsAoLUlwwCTFQDQJruD3LQVANDakmGAyQoAaJPdQW7aCgBobckwwGQFALTJ7iA3bQUAtLZkGGCyAgedsWJyosgNCrhRADO0G5XQJzQKAOjQWIVE3Sjwf+viUf6MTOJGAAAAAElFTkSuQmCC"
                }
            },
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca id='keras'\u003e\u003c/a\u003e\n",
                "## Keras [^](#contents \"Back to Contents\")\n",
                "![image.png](attachment:ec1d1aa0-3e29-4734-9171-fa26d58ed5cb.png)\n",
                "\n",
                "From our work in the previous sections of this notebook I'm sure you can now appreciate that implementing a non-trivial CNN by hand would be a pain, and the looping code above was far from optimized. So we will be using \u003ca href='https://keras.io/'\u003eKeras\u003c/a\u003e to quickly construct our neural networks.\n",
                "\n",
                "The Keras API that sits on top of Tensorflow. It allows user to work at a more intuitive level of abstraction where the basic objects are **layers**."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"keras_layers\" class='exercise'\u003e\u003cb\u003eLayers of a CNN in Keras\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e\n",
                "\u003cimg src='fig/cnn1.png' width='900px'\u003e\n",
                "\n",
                "The following is a list of layers commonly used when building CNNs with Keras.\u003cbr\u003e\n",
                "A link to the official documentation for each layer is also provided."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Input\n",
                "\n",
                "[**tf.keras.Input**](https://www.tensorflow.org/api_docs/python/tf/keras/Input)(\n",
                "    shape=None, **kwargs\n",
                ")\n",
                "\n",
                "\u003cdiv style='color:red'\u003e\u003cstrong\u003eThe input is not a layer!\u003c/strong\u003e\u003c/div\u003e\n",
                "\n",
                "As Pavlos said in lecture, you shouldn't think of the input to your network as a layer. Unfortunately, in Keras, most components of a network are referred to as 'layers'. Someone must have come to their senses because now `Input` can be found in the base `tf.keras` module. While it *can* still be imported from `tf.keras.layers`, we are civilized people and shall speak no more of that.\n",
                "\n",
                "The network will be expecting input of fixed shape which must be specified with the `shape` parameter. You should look at the data you are using to determine this shape.\n",
                "\n",
                "Adding an explicit `Input` object to your layer is not required as most layers have an `input_shape` that can be specified if they are the first layer in the network.\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2D Convolutional Layers\n",
                "\n",
                "[**keras.layers.Conv2D**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) (filters, kernel_size, strides=(1, 1), padding='valid', activation=None, use_bias=True, \n",
                "                    kernel_initializer='glorot_uniform', data_format='channels_last', \n",
                "                    bias_initializer='zeros')\n",
                "\n",
                "\u003cimg src='fig/conv-many-filters.png' width='550px'\u003e"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Some quick review if skipping to this section:**\n",
                "\n",
                "A convolutional layer is composed of **filters**, which are composed of **kernels** which are themselves composed of **weights**. Each filter also has a bias term though it is often not depicted in diagrams (it is exluded in the one above for example). We learn the weights and biases from our data. Each conv layer also has an associated **activation function** such as ReLU or sigmoid. \n",
                "\n",
                "The **number of filters** and the **height and width of the kernels** of which they consist are set by the `filters` and `kernel_size` (a tuple) arguments respectively. \n",
                "\n",
                "The **depth of the filters is fixed** by the depth (i.e., 'channels' or 'filter maps') of the input to the conv layer. \n",
                "\n",
                "The output of the conv layer is is a 3D tensor which is a set of **feature maps**. Each feature map is itself the output of one of the layer's filters convolving on the input. The height and width of the feature map tensor is determined by the input size, `kernel_size`, `padding`, and `stride`. The depth of the output tensor (i.e, number of feature maps) is equal to the number of filters in the layer.\n",
                "                    \n",
                "Keras also has a [1D convolutional layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D) used for time series data and a [3D convolutional layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv3D) used for video."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pooling Layers\n",
                "\n",
                "[**keras.layers.MaxPool2D**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)(pool_size=(2, 2), strides=None, padding='valid', data_format=None)\n",
                "\n",
                "\u003cimg src='fig/maxpool.png' alt='MaxPool' width='400px'\u003e\n",
                "\n",
                "Pooling layers are also comprised of filters and feature maps. Let's say the pooling layer has a 2x2 receptive field and a stride of 2. This stride results in feature maps that are one half the size of the input feature maps. We can use a max() operation for each receptive field. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Dropout Layers\n",
                "\u003cimg src='fig/dropout.gif' width='200px'\u003e\n",
                "\n",
                "[**tf.keras.layers.Dropout**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)(rate, seed=None)\n",
                "\n",
                "Dropout consists in randomly setting a fraction of input units to 0 at each update during training time. In Keras this fraction is set by the `rate` parameter. At inference time, trained weights are multipled by $(1 - \\text{rate})$. Dropout often used to help prevent overfitting by limiting the complexity of our model. It can also prevent groups of neurons from 'conspiring' together to have a large affect on the out put, something traditional forms of weight regularization would not catch.\n",
                "\n",
                "**Caution:** Dropout's behavior is not the same if performed after a convolutional layer! [See this post for more information](https://towardsdatascience.com/dropout-on-convolutional-layers-is-weird-5c6ab14f19b2).\n",
                "\n",
                "**Q:** Why might it make sense to think of dropout as a type of ensemble method? 🤔\n",
                "\n",
                "References\u003cbr\u003e\n",
                "[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Flatten Layers\n",
                "\n",
                "\n",
                "[**keras.layers.Flatten**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)()\n",
                "\n",
                "Like `Input` and `Dropout`, `Flatten` is not a layer in the traditional sense. It has no learned parameters and no parameters other than `input_shape`. Its only function is to flatten its multi-dimensional input into a flat vector. The flatten layer sits between our final 2D output (either from Conv2D or MaxPool2D) and our first fully connected, `Dense` layer.\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Global Average Pooling Layers\n",
                "\n",
                "[**keras.layers.GlobalAveragePooling2D**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D)()\n",
                "\n",
                "The GlobalAveragePooling2D layer is a type of pooling layer that is commonly used in convolutional neural networks (CNNs), particularly towards the end of the network, before the final classification layers as an alternative to `Flatten`.\n",
                "\n",
                "**What is Global Average Pooling (GAP)?**\n",
                "\n",
                "Global Average Pooling (GAP) is an operation that calculates the average value of each feature map in the previous layer. Unlike traditional pooling layers that operate on local regions (e.g., 2x2 pools), GAP processes the entire feature map. For a given feature map, GAP outputs a single average value, effectively reducing the spatial dimensions (width and height) of the feature map to 1. If a convolutional layer outputs H x W x C feature maps (H being height, W width, and C channels or depth), applying GAP will reduce this to 1 x 1 x C, transforming spatial features into a flat vector.\n",
                "\n",
                "**Why Use Global Average Pooling?**\n",
                "\n",
                "- **Reduces Overfitting:** By summarizing the spatial information, GAP reduces the total number of parameters in the model. This simplification can help prevent overfitting, as there are fewer parameters to learn compared to when using fully connected layers directly after convolutional layers.\n",
                "\n",
                "- **Seamless Transition to Classification:** By outputting a flat vector that corresponds to the number of feature maps, GAP provides an efficient way to transition from convolutional layers (which are good at extracting spatial features) to dense layers (used for classification). The output of GAP can be directly fed into a dense layer without the need for reshaping or flattening."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Fully Connected Layers.\n",
                "\n",
                "[**keras.layers.Dense**](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)(units, activation=None, use_bias=True, \n",
                "                    kernel_initializer='glorot_uniform', bias_initializer='zeros')\n",
                "                    \n",
                "\u003cimg src='fig/dense.png' width='250px'\u003e\n",
                "\n",
                "Most CNNs have of one or more dense layers at the end with the final layer referred to as the **output layer**. You'll need to specify the number of `units` in each layer (sometimes called 'neurons' or 'nodes') as well as the `activation`. \n",
                "\n",
                "*Special care should be taken in deciding on the activation function for the output layer!* The correct choice of activation in this final layer depends on the task we are training our model to perform. For example, a linear activation for regression, but a sigmoid for binary classification.\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca id='kmnist'\u003e\u003c/a\u003e\n",
                "## Revisting KMNIST [^](#contents \"Back to Contents\")\n",
                "\n",
                "Let's try to put some of our new tools to work by building a CNN classifer for the KMNIST dataset from HW3."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import keras"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Ensure replicable results\n",
                "import os\n",
                "import random as rn\n",
                "SEED = 109\n",
                "tf.random.set_seed(SEED)\n",
                "os.environ['PYTHONHASHSEED'] = '0'\n",
                "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
                "tf.random.set_seed(SEED)\n",
                "np.random.seed(SEED)\n",
                "rn.seed(SEED)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# your code here\n",
                "X_kmnist_train = pd.read_csv(\"kmnist/kmnist_train.csv.zip\").drop(columns=\"output\").values\n",
                "y_kmnist_train = pd.read_csv(\"kmnist/kmnist_train.csv.zip\")[\"output\"].values\n",
                "\n",
                "X_kmnist_test = pd.read_csv(\"kmnist/kmnist_test.csv.zip\").values\n",
                "\n",
                "# reshape both X frames for proper pixel representation in imshow plots\n",
                "X_kmnist_train = X_kmnist_train.reshape(-1, 28, 28, 1)/255.\n",
                "X_kmnist_test = X_kmnist_test.reshape(-1, 28, 28, 1)/255.\n",
                "\n",
                "print(\n",
                "    \"The shapes of the Kannada MNIST X and y datasets are:\\n\\n\"\n",
                "    \"\\tX train\\t{}\\n\\ty train\\t{}\\n\\n\\tX TEST\\t{}\".format(\n",
                "        X_kmnist_train.shape, y_kmnist_train.shape, X_kmnist_test.shape\n",
                "    )\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's just remind ourselves what the dataset looks like."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "idx_list = [2, 1]\n",
                "\n",
                "fig, axes = plt.subplots(1,2, figsize=(6,3.5))\n",
                "\n",
                "plt.suptitle(\n",
                "    \"Sample KMNIST training characters\",\n",
                "    y=1,\n",
                "    fontsize=18,\n",
                ")\n",
                "\n",
                "for idx, ax in zip(idx_list, axes.flat):\n",
                "    ax.imshow(X_kmnist_train[idx], cmap=\"gray\")\n",
                "    ax.set_xticks([])\n",
                "    ax.set_yticks([])\n",
                "    ax.set_title(\n",
                "        \"class label: {}\".format(y_kmnist_train[idx]),\n",
                "        fontsize=14,\n",
                "    )\n",
                "\n",
                "plt.tight_layout();"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_kmnist_train.shape, X_kmnist_test.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, GaussianNoise\n",
                "from keras.layers import GlobalAveragePooling2D, Input, MaxPool2D, RandomRotation, UpSampling2D\n",
                "from keras.models import Model, Sequential\n",
                "from keras import losses\n",
                "from keras import optimizers\n",
                "from keras import layers\n",
                "from keras import callbacks"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"baseline\" class='exercise'\u003e\u003cb\u003eBaseline Classifer\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "inp = Input(shape=(28,28,1))\n",
                "x = Conv2D(64, 2, activation='relu', padding='same')(inp)\n",
                "x = MaxPool2D(2)(x)\n",
                "x = Conv2D(32, 2, activation='relu', padding='same')(x)\n",
                "x = MaxPool2D(2)(x)\n",
                "x = Conv2D(16, 2, activation='relu', padding='same')(x)\n",
                "x = MaxPool2D(2)(x)\n",
                "x = Flatten()(x)\n",
                "x = Dense(64, activation='relu')(x)\n",
                "out = Dense(1, activation='sigmoid')(x)\n",
                "\n",
                "baseline = Model(inputs=[inp], outputs=out)\n",
                "baseline.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# import tensorflow as tf\n",
                "# tf.data.experimental.enable_debug_mode()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "baseline.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "baseline.fit(X_kmnist_train,\n",
                "             y_kmnist_train,\n",
                "             validation_split=.2,\n",
                "             batch_size=64,\n",
                "             callbacks=es,\n",
                "             epochs=50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_hist(model, title=None):\n",
                "    fig, axs = plt.subplots(1,2, figsize=(12,5))\n",
                "    axs[0].plot(model.history.history['loss'], label='train')\n",
                "    axs[0].plot(model.history.history['val_loss'], label='val')\n",
                "    axs[0].axvline(np.argmin(model.history.history['val_loss']), c='k', ls=':', label='final model')\n",
                "    axs[0].set_xlabel('Epoch')\n",
                "    axs[0].set_ylabel('BCE Loss')\n",
                "    axs[0].legend()\n",
                "    axs[1].plot(model.history.history['accuracy'], label='train')\n",
                "    axs[1].plot(model.history.history['val_accuracy'], label='val')\n",
                "    axs[1].axvline(np.argmin(model.history.history['val_loss']), c='k', ls=':', label='final model')\n",
                "    axs[1].legend();\n",
                "    axs[1].set_xlabel('Epoch')\n",
                "    axs[1].set_ylabel('ACC')\n",
                "    plt.suptitle(title)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_hist(baseline, 'Baseline KMNIST Classifier')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_kmnist_test = pd.read_csv('kmnist/solution_kaggle.csv')['category'].values\n",
                "\n",
                "baseline.evaluate(X_kmnist_test, y_kmnist_test)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"improving\" class='exercise'\u003e\u003cb\u003eImproving on the Baseline\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# your code here\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca id='tfdatasets'\u003e\u003c/a\u003e\n",
                "\n",
                "## Tensorflow Datasets [^](#contents \"Back to Contents\")\n",
                "\u003cimg src='https://3.bp.blogspot.com/-d-nV7xJRmpw/Xo328dcAx3I/AAAAAAAAC7Q/qlqJOle6XIosJ3CGIDJ04F3Voh1iXDg0gCLcBGAsYHQ/s1600/TF_FullColor_Icon.jpg' width='150'\u003e\n",
                "\n",
                "TensorFlow Datasets (TFDS) is a collection of datasets ready to use, with TensorFlow or other Python ML frameworks. These datasets are exposed as `tf.data.Dataset` objects, enabling easy-to-use and high-performance input pipelines."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "import tensorflow_datasets as tfds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Better performance with the tf.data API\n",
                "# Reference: https://www.tensorflow.org/guide/datac_performance\n",
                "AUTOTUNE = tf.data.experimental.AUTOTUNE"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"loadds\" class='exercise'\u003e\u003cb\u003eLoading Datasets\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e\n",
                "\n",
                "TFDS gives us access to dozens of research quality datasets with the simple `tfds.load` method.\u003cbr\u003e\n",
                "An extensive catalogue of datasets can be seen \u003ca href='https://www.tensorflow.org/datasets/catalog/overview'\u003ehere\u003c/a\u003e. You can even \u003ca href='https://www.tensorflow.org/datasets/add_dataset'\u003ewrite your own custom dataset\u003c/a\u003e.\n",
                "\n",
                "### \u003cdiv style='font-size: 150%'\u003e🐎 or 🧍?\u003c/div\u003e\n",
                "\n",
                "But it doesn't mean you should just because you can. The *bizzare* \u003ca href='http://laurencemoroney.com/horses-or-humans-dataset'\u003eHorses or Humans\u003c/a\u003e dataset may just be an example of this.\u003cbr\u003e\n",
                "Our call to `tfds.load` will use several arguments:\n",
                "- `name`: (str) the dataset to load (you can look these up in the above catalogue)\n",
                "- `split`: (list) some datasets have pre-specified splits; this list defines which splits to load\n",
                "- `shuffle_files`: (bool) files are loaded in random order\n",
                "- `as_supervised`: (bool) loads labels if dataset has them\n",
                "- `with_info`: (bool) also returns an DatasetInfo object with details about the loaded dataset\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "tfds.disable_progress_bar()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "(ds_train, ds_test), ds_info = tfds.load(name=\"horses_or_humans\", split=['train', 'test'],\n",
                "                                         shuffle_files=True, as_supervised=True, with_info=True, )"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The `ds_info` we got from using `with_info=True` gives us a great overview of some facts about the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "ds_info"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"dsobj\" class='exercise'\u003e\u003cb\u003eThe Dataset Object\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e\n",
                "\n",
                "We'll be working with closely with the `tf.data.Dataset` object so we should learn more about its methods and structure."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Some Python Arcana: Iterables \u0026 Iterators**:\u003cbr\u003e\n",
                "\n",
                "The `tf.data.Dataset` object is an *iterable*, which means it implements an `__iter__` method which returns an *iterator* object.\u003cbr\u003e\n",
                "An *iterator* is an object that implements a `__next__` method which returns the next element in the iterator!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create iterator from iterable\n",
                "my_iter = iter(ds_train)\n",
                "my_iter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# get next element from iterator\n",
                "next_one = next(my_iter)\n",
                "print(f'Each element in the iterator is of type {type(next_one)} with length {len(next_one)}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# display element from iterator\n",
                "next_one"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Inspecting this tuple we see the 1st element is our image and the 2nd is the lable. Let's visualize the image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "image, label = next_one\n",
                "plt.imshow(image)\n",
                "plt.title(int(label));"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It appears humans are the positive class. Let's make a dictionary to map class labels to strings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create human interperatable class names\n",
                "class_names = {0: 'horse', 1: 'human'}"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Iterating**\n",
                "\n",
                "Iterables can be looped over with a `for` loop. And while you *can* loop over the `Dataset` iterable object itself it is more common to first use the `as_numpy_iterator()` method if running TF in eager mode."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "rows = 3\n",
                "cols = 5\n",
                "fig, ax = plt.subplots(rows, cols, figsize=(10,6))\n",
                "for ax, (img, label) in zip(ax.ravel(), ds_train.as_numpy_iterator()):\n",
                "    # break when no more axes left\n",
                "    if ax is None:\n",
                "        break\n",
                "    ax.imshow(img)\n",
                "    ax.set_title(class_names[label])\n",
                "    ax.axis('off')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The above method works, but it would be a nuisance to have to always write out all that code just to inspect our datasets.\n",
                "\n",
                "Luckily, `tfds` has a much faster way to do this with the `show_examples()` method."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# train examples\n",
                "tfds.show_examples(ds_train, ds_info, rows=rows, cols=cols);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# test examples\n",
                "tfds.show_examples(ds_test, ds_info, rows=rows, cols=cols);"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Q:** Do you notice anything strange about the test examples? 🤔"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"take\" class='exercise'\u003e\u003cb\u003eTake, Cardinality, \u0026 Batch\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e\n",
                "\n",
                "**Take**\n",
                "\n",
                "We can use the `take()` method to return a **subset** of the original `Dataset` object of a desired **cardinality**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# get a subset with cardinality 2\n",
                "my_subset = ds_train.take(2)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Cardinality**\n",
                "\n",
                "It's true that we can check the length of a datset with `len()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# one way to find a Dataset's length\n",
                "len(my_subset)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "But this is inefficient  for larger datasets.\u003cbr\u003e\n",
                "It is preferable to use the `cardinality()` method. This returns a Tensor."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# a better way\n",
                "cardinality = my_subset.cardinality()\n",
                "print(f'Cardinality Type: {type(cardinality)}')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It looks a bit strange when displayed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# displaying an EagerTensor\n",
                "cardinality"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "But it behaves just like an integer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# no surprises here!\n",
                "(cardinality + 2) == 4"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And if you really want to, you can always convert it to a `numpy.int64` object which prints nicely."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# convert to nump.int64\n",
                "cardinality.numpy()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Batch**\n",
                "\n",
                "To get the benefits of \u003ca href='https://en.wikipedia.org/wiki/Stochastic_gradient_descent'\u003e**stochastic gradient descent**\u003c/a\u003e (SGD) during training, we'd like to feed elements from the dataset into our model in batches.\u003cbr\u003e\n",
                "This is handled by the `batch()` method.\n",
                "\n",
                "**Q:** What are some benefits of SGD? 🤔"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "BATCH_SIZE = 32\n",
                "num_batch = ds_train.cardinality() / BATCH_SIZE\n",
                "print(f'Number of Potential Batches of size {BATCH_SIZE}:', num_batch.numpy())\n",
                "num_batched_produced = ds_train.batch(BATCH_SIZE).cardinality()\n",
                "print(f'Number of Batches of size {BATCH_SIZE} Produced:', num_batched_produced.numpy())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Q:** Why don't these numbers match? What's going on? 🤔"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The batched dataset is itself a `Dataset`, but now it's an iterable that produces batches.\u003cbr\u003e\n",
                "In a **supervised** situation like ours, each batch is a tuple."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "# inspect first batch\n",
                "my_batch = ds_train.batch(BATCH_SIZE).as_numpy_iterator().next()\n",
                "print(f'Each batch is of type {type(my_batch)} with length {len(my_batch)}')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The 1st element of the tuple are all the images in the batch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# batch images\n",
                "my_batch[0].shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The 2nd element are all the labels in the batch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# batch labels\n",
                "my_batch[1].shape"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Note:** The batch of images and labels above are both `numpy` arrays. This is because we used `as_numpy_iterator()` on our batched dataset. This is why we were able to use the `shape` attribute. here."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also strengthen our intuition about the structure of the batched dataset by iterating over the batches and displaying the first image in each."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# display the first image in each batch\n",
                "fig, axs = plt.subplots(4, 8, figsize=(9,5))\n",
                "axs = axs.ravel()\n",
                "for i, (img_batch, label_batch) in enumerate(ds_train.batch(BATCH_SIZE, drop_remainder=True)):\n",
                "    for (img, label) in zip(img_batch, label_batch):\n",
                "        axs[i].imshow(img)\n",
                "        axs[i].set_title(f'batch {i+1}')\n",
                "        axs[i].axis('off')\n",
                "        break\n",
                "plt.tight_layout()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"cache\" class='exercise'\u003e\u003cb\u003eCache, Prefetch \u0026 Shuffle\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e\n",
                "\n",
                "There are helpful methods we can use to optimize the training process. Most of these descriptions are adapted from the TensorFlow documentation. As always, the documentation is the best place to go if you'd like a deeper understanding.\n",
                "\n",
                "**\u003ca href=\"https://www.tensorflow.org/guide/data_performance#caching\"\u003e`Cache`\u003c/a\u003e** caches a dataset, either in memory or on local storage. This will save some operations (like file opening and data reading) from being executed during each epoch. (perhaps not a good idea for enormous datasets)\n",
                "\n",
                "**`Prefetching`** overlaps the preprocessing and model execution of a training step. While the model is executing training steps, the input pipeline is reading the data for step s+1. Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data.\"\n",
                "\n",
                "**\u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle\"\u003e`Shuffle`\u003c/a\u003e** Randomly shuffles the elements of this dataset.\n",
                "\n",
                "**Note:** cache will produce exactly the same elements during each iteration through the dataset. If you wish to randomize the iteration order, make sure to call shuffle after calling cache."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And of course we can chain all these commands together!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "images, labels = ds_train.cache()\\\n",
                "                         .shuffle(buffer_size=ds_train.cardinality(), seed=SEED, reshuffle_each_iteration=True)\\\n",
                "                         .batch(BATCH_SIZE).prefetch(AUTOTUNE)\\\n",
                "                         .as_numpy_iterator().next() # one batch\n",
                "# show first image in batch\n",
                "plt.imshow(images[0])\n",
                "plt.title(class_names[labels[0]])\n",
                "plt.axis('off');"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"dspreproc\" class='exercise'\u003e\u003cb\u003ePreprocessing with Datasets\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e\n",
                "\n",
                "Often, we'll want to **preprocess** our data in some way before feeding it into our model.\u003cbr\u003e\n",
                "We can use use the `Dataset` object's `map` method to perform arbitrary functions on the elements of the dataset.\n",
                "\n",
                "Because the result of the `map` operation is itself a dataset object, we can continue to chain these commands one after another.\u003cbr\u003e\n",
                "Here we are normalizing and resizing our images as part of the preprocessing stage using functions of our own design. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "H = W = 224\n",
                "\n",
                "def normalize_img(img, label):\n",
                "    return tf.cast(img, tf.float32)/255.0, label\n",
                "\n",
                "def resize_img(img, label):\n",
                "    return tf.image.resize(img, size=[H, W]), label\n",
                "\n",
                "def preprocess(img, label):\n",
                "    img, label = normalize_img(img, label)\n",
                "    img, label = resize_img(img, label)\n",
                "    return img, label\n",
                "\n",
                "ds_train = ds_train.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
                "ds_test = ds_test.map(preprocess, num_parallel_calls=AUTOTUNE)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"dataaug\" class='exercise'\u003e\u003cb\u003eData Augmentation\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e\n",
                "\n",
                "\n",
                "We almost always wish we had *more data*! But it can be expensive and time consuming to gather and label new data.\u003cbr\u003e\n",
                "So why not **simulate new data?** We can accomplish this by creating variants of our original data. \n",
                "\n",
                "In the case of images this is very intuitive. Simply rotate your picture of a horse. It's still a horse, but the rotated image is likely different from anything in your data original. As long as the simulated data is not *too* different from the sort of example's we'd like to learn, this can help our model generalize better to previously unseen examples not in the original dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow_addons as tfa\n",
                "\n",
                "def random_rotate(image, label):\n",
                "    \"\"\"Dataset pipe that rotates an image, helper function to augment below\"\"\"\n",
                "    shape = image.shape\n",
                "    deg = tf.random.uniform([],-10.,10.)\n",
                "    image = tfa.image.rotate(image, deg/180.*np.pi, interpolation=\"BILINEAR\")\n",
                "    image.set_shape((shape))\n",
                "    label.set_shape(())\n",
                "    return image, label\n",
                "\n",
                "def random_zoom(image, label):\n",
                "    \"\"\"Dataset pipe that zooms an image, helper function to augment below\"\"\"\n",
                "    rand_float = tf.random.uniform([],10,20)\n",
                "    rand_int = tf.cast(rand_float, tf.int32)\n",
                "    image = tf.image.resize_with_crop_or_pad(image,\n",
                "                                             H + H//rand_int,\n",
                "                                             W + W//rand_int)\n",
                "    image = tf.image.random_crop(image, size=[H, W, 3])\n",
                "    return image, label\n",
                "    \n",
                "def augment(image, label):\n",
                "    \"\"\"Function that randomly alters an image with\n",
                "       flipping, rotation, zoom, and contrast adjustment\"\"\"\n",
                "    image = tf.image.random_flip_left_right(image)\n",
                "    image, label = random_rotate(image, label)\n",
                "    # image, label = random_zoom(image, label)\n",
                "    # image = tf.image.random_contrast(image, lower=.95, upper=1.)\n",
                "    \n",
                "    return image, label"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here are just a few examples created using the augmentation functions defined above!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# display a batch of altered images\n",
                "fig, axs = plt.subplots(4,4, figsize=(6,6))\n",
                "aug_batch = ds_train.map(augment, num_parallel_calls=AUTOTUNE).take(16)\n",
                "for ax, (img, label) in zip(axs.ravel(), aug_batch):\n",
                "    ax.imshow(img)\n",
                "    ax.axis('off')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Data augmentation is an important topic and it will be revisited several times throughout the course!"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"val_split\" class='exercise'\u003e\u003cb\u003eCreating a Validation Set\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e\n",
                "\n",
                "We can see from `ds_info` above that this dataset had predefined train and test sets. We loaded both.\n",
                "\n",
                "Some TF datasets also have a validation set. Others have only train. We'd like to use a validation set while training our model. And in situations where your data set only has a train set it will be important to know how to create new splits. As of Tensorflow 2.10 this is made easy with the `tf.keras.utils.split_dataset()` methods which works similar to the train_test_split in SKLearn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "left_ds, right_ds = keras.utils.split_dataset(ds_train, left_size=0.8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "left_ds.cardinality() + right_ds.cardinality() == ds_train.cardinality()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003ca id='transfer_learning'\u003e\u003c/a\u003e\n",
                "## Transfer Learning [^](#contents \"Back to Contents\")\n",
                "\n",
                "Here we can see an example of transfer learning where we use the pretrained MobileNet model as the base of our classifier."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cdiv id=\"mobilenet\" class='exercise'\u003e\u003cb\u003eMobileNet\u003c/b\u003e\u003c/div\u003e\u003c/br\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds_train, ds_info = tfds.load('horses_or_humans', split='train', as_supervised=True, with_info=True)\n",
                "ds_test = tfds.load('horses_or_humans', split='test', as_supervised=True)\n",
                "ds_train, ds_val = keras.utils.split_dataset(ds_train, left_size=0.8)\n",
                "\n",
                "def preprocess(image, label):\n",
                "    image = tf.image.resize(image, (224, 224))\n",
                "    image = tf.keras.applications.mobilenet.preprocess_input(image)\n",
                "    return image, label\n",
                "\n",
                "ds_train = ds_train.map(preprocess).map(augment).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
                "ds_val = ds_val.map(preprocess).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
                "ds_test = ds_test.map(preprocess).batch(32).prefetch(tf.data.experimental.AUTOTUNE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
                "                                                include_top=False,\n",
                "                                                weights='imagenet')\n",
                "\n",
                "# Freeze the base model's layers to prevent them from being updated during training\n",
                "base_model.trainable = False\n",
                "\n",
                "# Add custom layers on top of MobileNet\n",
                "x = base_model.output\n",
                "x = keras.layers.GlobalAveragePooling2D()(x)\n",
                "# Add a fully-connected layer\n",
                "x = keras.layers.Dense(1024, activation='relu')(x)\n",
                "# Add a logistic layer for binary classification\n",
                "predictions = keras.layers.Dense(1, activation='sigmoid')(x)\n",
                "\n",
                "# This is the model we will train\n",
                "model = Model(inputs=base_model.input, outputs=predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
                "              loss='binary_crossentropy',\n",
                "              metrics=['accuracy'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.fit(ds_train,\n",
                "          validation_data=ds_val,\n",
                "          epochs=10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.evaluate(ds_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        }
    ]
}
